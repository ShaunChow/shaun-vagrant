---
# Source: vitess/templates/vitess.yaml
# Create global resources.
---
# create a single vttablet service
# set tuple values to more recognizable variables
apiVersion: v1
kind: Service
metadata:
  name: vttablet
  labels:
    app: vitess
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  publishNotReadyAddresses: true
  ports:
    - port: 15002
      name: web
    - port: 16002
      name: grpc

  clusterIP: None
  selector:
    app: vitess
    component: vttablet
---




# create an etcd cluster for the global topology# set tuple values to more recognizable variables

###################################
# EtcdCluster
###################################
apiVersion: "etcd.database.coreos.com/v1beta2"
kind: "EtcdCluster"
metadata:
  name: "etcd-global"
  ## Adding this annotation make this cluster managed by clusterwide operators
  ## namespaced operators ignore it
  annotations:
    etcd.database.coreos.com/scope: clusterwide
  
spec:
  size: 1
  version: "3.3.10"
  pod:
    resources:
      requests:
        cpu: 100m
        memory: 50Mi
      
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        # prefer to stay away from other same-cell etcd pods
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                etcd_cluster: "etcd-global"

# Create requested resources in each cell.


---
# create an etcd cluster per cell# set tuple values to more recognizable variables

###################################
# EtcdCluster
###################################
apiVersion: "etcd.database.coreos.com/v1beta2"
kind: "EtcdCluster"
metadata:
  name: "etcd-zone1"
  ## Adding this annotation make this cluster managed by clusterwide operators
  ## namespaced operators ignore it
  annotations:
    etcd.database.coreos.com/scope: clusterwide
  
spec:
  size: 1
  version: "3.3.10"
  pod:
    resources:
      requests:
        cpu: 100m
        memory: 50Mi
      
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        # prefer to stay away from other same-cell etcd pods
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                etcd_cluster: "etcd-zone1"
---
# create one controller per cell
# set tuple values to more recognizable variables# define image to use

###################################
# vtctld Service
###################################
kind: Service
apiVersion: v1
metadata:
  name: vtctld
  labels:
    component: vtctld
    app: vitess
spec:
  ports:
    - name: web
      port: 15000
    - name: grpc
      port: 15999
  selector:
    component: vtctld
    app: vitess
  type: NodePort
---
###################################
# vtctld Service + Deployment
###################################
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: vtctld
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vitess
      component: vtctld
  template:
    metadata:
      labels:
        app: vitess
        component: vtctld
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 2000
      # set tuple values to more recognizable variables
      containers:
        - name: vtctld
          image: dockerhub.azk8s.cn/vitess/vtctld:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
          readinessProbe:
            httpGet:
              path: /debug/health
              port: 15000
            initialDelaySeconds: 30
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /debug/status
              port: 15000
            initialDelaySeconds: 30
            timeoutSeconds: 5
          env:
            
          volumeMounts:
            
            
          resources:
            requests:
              cpu: 100m
              memory: 50Mi
            
          command:
            - bash
            - "-c"
            - |
              set -ex;

              

              eval exec /vt/bin/vtctld $(cat <<END_OF_COMMAND
                -cell="zone1"
                -web_dir="/vt/web/vtctld"
                -web_dir2="/vt/web/vtctld2/app"
                -workflow_manager_init
                -workflow_manager_use_election
                -logtostderr=true
                -stderrthreshold=0
                -port=15000
                -grpc_port=15999
                -service_map="grpc-vtctl"
                -topo_implementation="etcd2"
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -topo_global_root=/vitess/global
                
                
                  
                
                
                
              END_OF_COMMAND
              )

      volumes:
        
        
---
# create a pool of vtgates per cell
# set tuple values to more recognizable variables# define image to use

###################################
# vtgate Service
###################################
kind: Service
apiVersion: v1
metadata:
  name: vtgate-zone1
  labels:
    component: vtgate
    cell: zone1
    app: vitess
spec:
  ports:
    - name: web
      port: 15001
    - name: grpc
      port: 15991

    - name: mysql
      port: 3306

  selector:
    component: vtgate
    cell: zone1
    app: vitess
  type: NodePort
---
###################################
# vtgate Deployment
###################################
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: vtgate-zone1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vitess
      component: vtgate
      cell: zone1
  template:
    metadata:
      labels:
        app: vitess
        component: vtgate
        cell: zone1
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 2000
      # set tuple values to more recognizable variables
      
      # affinity pod spec
      affinity:
        
      
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # prefer to be scheduled with same-cell vttablets
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vttablet"
                  cell: "zone1"
      
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # prefer to stay away from other same-cell vtgates
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vtgate"
                  cell: "zone1"



      initContainers:
        
        
        - name: init-mysql-creds
          image: "dockerhub.azk8s.cn/vitess/vtgate:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: creds
              mountPath: "/mysqlcreds"
          env:
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: myuser-password
                  key: password
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              creds=$(cat <<END_OF_COMMAND
              {
                "myuser": [
                  {
                    "UserData": "myuser",
                    "Password": "$MYSQL_PASSWORD"
                  }
                ],
                "vt_appdebug": []
              }
              END_OF_COMMAND
              )
              echo $creds > /mysqlcreds/creds.json



      containers:
        - name: vtgate
          image: dockerhub.azk8s.cn/vitess/vtgate:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
          readinessProbe:
            httpGet:
              path: /debug/health
              port: 15001
            initialDelaySeconds: 30
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /debug/status
              port: 15001
            initialDelaySeconds: 30
            timeoutSeconds: 5
          volumeMounts:
            - name: creds
              mountPath: "/mysqlcreds"
            
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
            

          command:
            - bash
            - "-c"
            - |
              set -ex

              eval exec /vt/bin/vtgate $(cat <<END_OF_COMMAND
                -topo_implementation=etcd2
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -topo_global_root=/vitess/global
                -logtostderr=true
                -stderrthreshold=0
                -port=15001
                -grpc_port=15991

                -mysql_server_port=3306

                -mysql_auth_server_impl="static"
                -mysql_auth_server_static_file="/mysqlcreds/creds.json"


                -service_map="grpc-vtgateservice"
                -cells_to_watch="zone1"
                -tablet_types_to_wait="MASTER,REPLICA"
                -gateway_implementation="discoverygateway"
                -cell="zone1"
                -mysql_server_version="5.7.9-Vitess"
                
              END_OF_COMMAND
              )
      volumes:
        - name: creds
          emptyDir: {}
        
---
###################################
# vtgate PodDisruptionBudget
###################################
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: vtgate-zone1
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: vitess
      component: vtgate
      cell: zone1




  # Tablets for keyspaces
  

    # Keyspace initializations
    # sanitize inputs for labels# define image to use
---
###################################
# ApplySchema Job
###################################
apiVersion: batch/v1
kind: Job
metadata:
  name: commerce-apply-schema-initial
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: apply-schema
        image: "dockerhub.azk8s.cn/vitess/vtctlclient:helm-1.0.7-5"
        volumeMounts:
          

        command: ["bash"]
        args:
          - "-c"
          - |
            set -ex

            VTCTLD_SVC=vtctld.vitess:15999
            SECONDS=0
            TIMEOUT_SECONDS=600
            VTCTL_EXTRA_FLAGS=()

            # poll every 5 seconds to see if vtctld is ready
            until vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC ListAllTablets zone1 > /dev/null 2>&1; do
              if (( $SECONDS > $TIMEOUT_SECONDS )); then
                echo "timed out waiting for vtctlclient to be ready"
                exit 1
              fi
              sleep 5
            done

            while true; do
              if (( $SECONDS > $TIMEOUT_SECONDS )); then
                echo "timed out waiting for master"
                exit 1
              fi

              # wait for all shards to have a master
              master_alias=$(vtctlclient ${VTLCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC GetShard commerce/0 | jq '.master_alias.uid')
              if [ "$master_alias" == "null" -o "$master_alias" == "" ]; then
                  echo "no master for 'commerce/0' yet, continuing to wait"
                  sleep 5
                  continue
              fi

              break
            done

            vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC ApplySchema -sql "$(cat <<END_OF_COMMAND
              create table product(
                sku varbinary(128),
                description varbinary(128),
                price bigint,
                primary key(sku)
              );
              create table customer(
                customer_id bigint not null auto_increment,
                email varbinary(128),
                primary key(customer_id)
              );
              create table corder(
                order_id bigint not null auto_increment,
                customer_id bigint,
                sku varbinary(128),
                price bigint,
                primary key(order_id)
              );
            END_OF_COMMAND
            )" commerce
      volumes:
        

---
###################################
# ApplyVSchema job
###################################
apiVersion: batch/v1
kind: Job
metadata:
  name: commerce-apply-vschema-initial
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: apply-vschema
        image: "dockerhub.azk8s.cn/vitess/vtctlclient:helm-1.0.7-5"
        volumeMounts:
          

        command: ["bash"]
        args:
          - "-c"
          - |
            set -ex

            VTCTLD_SVC=vtctld.vitess:15999
            SECONDS=0
            TIMEOUT_SECONDS=600
            VTCTL_EXTRA_FLAGS=()

            # poll every 5 seconds to see if keyspace is created
            until vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC GetKeyspace commerce > /dev/null 2>&1; do
              if (( $SECONDS > $TIMEOUT_SECONDS )); then
                echo "timed out waiting for keyspace commerce to be ready"
                exit 1
              fi
              sleep 5
            done

            vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC ApplyVSchema -vschema "$(cat <<END_OF_COMMAND
              {
                "tables": {
                  "product": {},
                  "customer": {},
                  "corder": {}
                }
              }
            END_OF_COMMAND
            )" commerce
      volumes:
        

    

      
      # Shard initializations
      
# define image to use
---
###################################
# InitShardMaster Job
###################################
apiVersion: batch/v1
kind: Job
metadata:
  name: zone1-commerce-0-init-shard-master
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: vitess
        component: vttablet
        cell: "zone1"
        keyspace: "commerce"
        shard: "0"
        initShardMasterJob: "true"

    spec:
      restartPolicy: OnFailure
      containers:
      - name: init-shard-master
        image: "dockerhub.azk8s.cn/vitess/vtctlclient:helm-1.0.7-5"
        volumeMounts:
          

        command: ["bash"]
        args:
          - "-c"
          - |
            set -ex

            VTCTLD_SVC=vtctld.vitess:15999
            SECONDS=0
            TIMEOUT_SECONDS=600
            VTCTL_EXTRA_FLAGS=()

            # poll every 5 seconds to see if vtctld is ready
            until vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC ListAllTablets zone1 > /dev/null 2>&1; do
              if (( $SECONDS > $TIMEOUT_SECONDS )); then
                echo "timed out waiting for vtctlclient to be ready"
                exit 1
              fi
              sleep 5
            done

            until [ $TABLETS_READY ]; do
              # get all the tablets in the current cell
              cellTablets="$(vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC ListAllTablets zone1)"

              # filter to only the tablets in our current shard
              shardTablets=$( echo "$cellTablets" | awk 'substr( $5,1,16 ) == "zone1-commerce-0" {print $0}')

              # check for a master tablet from the ListAllTablets call
              masterTablet=$( echo "$shardTablets" | awk '$4 == "master" {print $1}')
              if [ $masterTablet ]; then
                  echo "'$masterTablet' is already the master tablet, exiting without running InitShardMaster"
                  exit
              fi

              # check for a master tablet from the GetShard call
              master_alias=$(vtctlclient ${VTLCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC GetShard commerce/0 | jq '.master_alias.uid')
              if [ "$master_alias" != "null" -a "$master_alias" != "" ]; then
                  echo "'$master_alias' is already the master tablet, exiting without running InitShardMaster"
                  exit
              fi

              # count the number of newlines for the given shard to get the tablet count
              tabletCount=$( echo "$shardTablets" | wc | awk '{print $1}')

              # check to see if the tablet count equals the expected tablet count
              if [ $tabletCount == 3 ]; then
                TABLETS_READY=true
              else
                if (( $SECONDS > $TIMEOUT_SECONDS )); then
                  echo "timed out waiting for tablets to be ready"
                  exit 1
                fi

                # wait 5 seconds for vttablets to continue getting ready
                sleep 5
              fi

            done

            # find the tablet id for the "-replica-0" stateful set for a given cell, keyspace and shard
            tablet_id=$( echo "$shardTablets" | awk 'substr( $5,1,26 ) == "zone1-commerce-0-replica-0" {print $1}')

            # initialize the shard master
            until vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC InitShardMaster -force commerce/0 $tablet_id; do
              if (( $SECONDS > $TIMEOUT_SECONDS )); then
                echo "timed out waiting for InitShardMaster to succeed"
                exit 1
              fi
              sleep 5
            done
      volumes:
        

      # Tablet initializations
      
        # set tuple values to more recognizable variables# sanitize inputs for labels# define images to use
---
###################################
# vttablet StatefulSet
###################################
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: "zone1-commerce-0-replica"
spec:
  serviceName: vttablet
  replicas: 2
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: vitess
      component: vttablet
      cell: "zone1"
      keyspace: "commerce"
      shard: "0"
      type: "replica"
  template:
    metadata:
      labels:
        app: vitess
        component: vttablet
        cell: "zone1"
        keyspace: "commerce"
        shard: "0"
        type: "replica"
    spec:
      terminationGracePeriodSeconds: 60000000
      securityContext:
        runAsUser: 1000
        fsGroup: 2000
      # set tuple values to more recognizable variables
      
      # affinity pod spec
      affinity:
        
      
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # prefer to be scheduled with same-cell vtgates
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vtgate"
                  cell: "zone1"
      
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # strongly prefer to stay away from same shard vttablets
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vttablet"
                  cell: "zone1"
                  keyspace: "commerce"
                  shard: "0"
      
          # prefer to stay away from any vttablets
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vttablet"

      initContainers:
        
        
        - name: "init-mysql"
          image: "dockerhub.azk8s.cn/vitess/mysqlctld:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
            - name: vt
              mountPath: "/vttmp"
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              # set up the directories vitess needs
              mkdir -p /vttmp/bin
              mkdir -p /vtdataroot/tabletdata
        
              # copy necessary assets to the volumeMounts
              cp /vt/bin/mysqlctld /vttmp/bin/
              cp /bin/busybox /vttmp/bin/
              cp -R /vt/config /vttmp/
        
              # make sure the log files exist
              touch /vtdataroot/tabletdata/error.log
              touch /vtdataroot/tabletdata/slow-query.log
              touch /vtdataroot/tabletdata/general.log
        
              # remove the old socket file if it is still around
              rm -f /vtdataroot/tabletdata/mysql.sock
              rm -f /vtdataroot/tabletdata/mysql.sock.lock
        
        
        - name: init-vttablet
          image: "dockerhub.azk8s.cn/vitess/vtctl:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              # Split pod name (via hostname) into prefix and ordinal index.
              hostname=$(hostname -s)
              [[ $hostname =~ ^(.+)-([0-9]+)$ ]] || exit 1
              pod_prefix=${BASH_REMATCH[1]}
              pod_index=${BASH_REMATCH[2]}
              # Prepend cell name since tablet UIDs must be globally unique.
              uid_name=zone1-$pod_prefix
              # Take MD5 hash of cellname-podprefix.
              uid_hash=$(echo -n $uid_name | md5sum | awk "{print \$1}")
              # Take first 24 bits of hash, convert to decimal.
              # Shift left 2 decimal digits, add in index.
              tablet_uid=$((16#${uid_hash:0:6} * 100 + $pod_index))
              # Save UID for other containers to read.
              echo $tablet_uid > /vtdataroot/tabletdata/tablet-uid
              # Tell MySQL what hostname to report in SHOW SLAVE HOSTS.
              echo report-host=$hostname.vttablet > /vtdataroot/tabletdata/report-host.cnf
              # Orchestrator looks there, so it should match -tablet_hostname above.
        
              # make sure that etcd is initialized
              eval exec /vt/bin/vtctl $(cat <<END_OF_COMMAND
                -topo_implementation="etcd2"
                -topo_global_root=/vitess/global
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -logtostderr=true
                -stderrthreshold=0
                UpdateCellInfo
                -server_address="etcd-global-client.vitess:2379"
                "zone1"
              END_OF_COMMAND
              )

      containers:
        
        
        - name: mysql
          image: "dockerhub.azk8s.cn/library/percona:5.7.26"
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command: ["mysqladmin", "ping", "-uroot", "--socket=/vtdataroot/tabletdata/mysql.sock"]
            initialDelaySeconds: 60
            timeoutSeconds: 10
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
            - name: vt
              mountPath: /vt
            
            
          resources:
              limits:
                cpu: 250m
                memory: 500Mi
              
          env:
            - name: VTROOT
              value: "/vt"
            - name: VTDATAROOT
              value: "/vtdataroot"
            - name: GOBIN
              value: "/vt/bin"
            - name: VT_MYSQL_ROOT
              value: "/usr"
            - name: PKG_CONFIG_PATH
              value: "/vt/lib"
        
            - name: VT_DB_FLAVOR
              valueFrom:
                configMapKeyRef:
                  name: vitess-cm
                  key: db.flavor
        
          lifecycle:
            preStop:
              exec:
                command:
                  - "bash"
                  - "-c"
                  - |
                    set -x
        
                    # block shutting down mysqlctld until vttablet shuts down first
                    until [ $VTTABLET_GONE ]; do
        
                      # poll every 5 seconds to see if vttablet is still running
                      /vt/bin/busybox wget --spider localhost:15002/debug/vars
        
                      if [ $? -ne 0 ]; then
                        VTTABLET_GONE=true
                      fi
        
                      sleep 5
                    done
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              if [ "$VT_DB_FLAVOR" = "percona" ]; then
                MYSQL_FLAVOR=Percona
              
              elif [ "$VT_DB_FLAVOR" = "mysql" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "mysql56" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "maria" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb103" ]; then
                MYSQL_FLAVOR=MariaDB103
              
              fi
              
              export MYSQL_FLAVOR
              
              
        
              eval exec /vt/bin/mysqlctld $(cat <<END_OF_COMMAND
                -logtostderr=true
                -stderrthreshold=0
                -tablet_dir "tabletdata"
                -tablet_uid "$(cat /vtdataroot/tabletdata/tablet-uid)"
                -socket_file "/vtdataroot/mysqlctl.sock"
                -init_db_sql_file "/vt/config/init_db.sql"
        
              END_OF_COMMAND
              )
        
        
        - name: vttablet
          image: "dockerhub.azk8s.cn/vitess/vttablet:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          readinessProbe:
            httpGet:
              path: /debug/health
              port: 15002
            initialDelaySeconds: 60
            timeoutSeconds: 10
          livenessProbe:
            httpGet:
              path: /debug/status
              port: 15002
            initialDelaySeconds: 60
            timeoutSeconds: 10
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
            
            
            
        
          resources:
              limits:
                cpu: 250m
                memory: 500Mi
              
          ports:
            - name: web
              containerPort: 15002
            - name: grpc
              containerPort: 16002
          env:
            - name: VTROOT
              value: "/vt"
            - name: VTDATAROOT
              value: "/vtdataroot"
            - name: GOBIN
              value: "/vt/bin"
            - name: VT_MYSQL_ROOT
              value: "/usr"
            - name: PKG_CONFIG_PATH
              value: "/vt/lib"
            
        
            - name: VT_DB_FLAVOR
              valueFrom:
                configMapKeyRef:
                  name: vitess-cm
                  key: db.flavor
        
          lifecycle:
            preStop:
              exec:
                command:
                  - "bash"
                  - "-c"
                  - |
                    set -x
        
                    VTCTLD_SVC=vtctld.vitess:15999
                    VTCTL_EXTRA_FLAGS=()
        
                    master_alias_json=$(/vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC GetShard commerce/0)
                    master_cell=$(jq -r '.master_alias.cell' <<< "$master_alias_json")
                    master_uid=$(jq -r '.master_alias.uid' <<< "$master_alias_json")
                    master_alias=$master_cell-$master_uid
        
                    current_uid=$(cat /vtdataroot/tabletdata/tablet-uid)
                    current_alias=zone1-$current_uid
        
                    if [ $master_alias != $current_alias ]; then
                        # since this isn't the master, there's no reason to reparent
                        exit
                    fi
        
                    # TODO: add more robust health checks to make sure that we don't initiate a reparent
                    # if there isn't a healthy enough replica to take over
                    # - seconds behind master
                    # - use GTID_SUBTRACT
        
                    RETRY_COUNT=0
                    MAX_RETRY_COUNT=100000
                    hostname=$(hostname -s)
        
                    # retry reparenting
                    until [ $DONE_REPARENTING ]; do
        
        
        
                      # reparent before shutting down
                      /vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC PlannedReparentShard -keyspace_shard=commerce/0 -avoid_master=$current_alias
        
        
        
                      # if PlannedReparentShard succeeded, then don't retry
                      if [ $? -eq 0 ]; then
                        DONE_REPARENTING=true
        
                      # if we've reached the max retry count, exit unsuccessfully
                      elif [ $RETRY_COUNT -eq $MAX_RETRY_COUNT ]; then
                        exit 1
        
                      # otherwise, increment the retry count and sleep for 10 seconds
                      else
                        let RETRY_COUNT=RETRY_COUNT+1
                        sleep 10
                      fi
        
                    done
        
                    # delete the current tablet from topology. Not strictly necessary, but helps to prevent
                    # edge cases where there are two masters
                    /vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC DeleteTablet $current_alias
        
        
        
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
        
              if [ "$VT_DB_FLAVOR" = "percona" ]; then
                MYSQL_FLAVOR=Percona
              
              elif [ "$VT_DB_FLAVOR" = "mysql" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "mysql56" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "maria" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb103" ]; then
                MYSQL_FLAVOR=MariaDB103
              
              fi
              
              export MYSQL_FLAVOR
              
              
              
        
              eval exec /vt/bin/vttablet $(cat <<END_OF_COMMAND
                -topo_implementation="etcd2"
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -topo_global_root=/vitess/global
                -logtostderr
                -port 15002
                -grpc_port 16002
                -service_map "grpc-queryservice,grpc-tabletmanager,grpc-updatestream"
                -tablet_dir "tabletdata"
                -tablet-path "zone1-$(cat /vtdataroot/tabletdata/tablet-uid)"
                -tablet_hostname "$(hostname).vttablet"
                -init_keyspace "commerce"
                -init_shard "0"
                -init_tablet_type "replica"
                -health_check_interval "5s"
                -mysqlctl_socket "/vtdataroot/mysqlctl.sock"
                -enable_replication_reporter
        
        
                -init_db_name_override "commerce"
        
        
        
        
                
                
                  
                
                
                -app_pool_size="40"
                -dba_pool_size="20"
                -queryserver-config-max-result-size="10000"
                -queryserver-config-pool-size="24"
                -queryserver-config-query-timeout="30"
                -queryserver-config-stream-pool-size="100"
                -queryserver-config-transaction-cap="300"
                
              END_OF_COMMAND
              )
        
        
        - name: logrotate
          image: dockerhub.azk8s.cn/vitess/logrotate:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: general-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/general.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: error-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/error.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: slow-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/slow-query.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot


      volumes:
        - name: vt
          emptyDir: {}
        
        
        


  volumeClaimTemplates:
    - metadata:
        name: vtdataroot
        annotations:
          null
          
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 500Mi
        

---
###################################
# vttablet PodDisruptionBudget
###################################
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: "zone1-commerce-0-replica"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: vitess
      component: vttablet
      cell: "zone1"
      keyspace: "commerce"
      shard: "0"
      type: "replica"

# conditionally add cron job
# set tuple values to more recognizable variables


      
        # set tuple values to more recognizable variables# sanitize inputs for labels# define images to use
---
###################################
# vttablet StatefulSet
###################################
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: "zone1-commerce-0-rdonly"
spec:
  serviceName: vttablet
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: vitess
      component: vttablet
      cell: "zone1"
      keyspace: "commerce"
      shard: "0"
      type: "rdonly"
  template:
    metadata:
      labels:
        app: vitess
        component: vttablet
        cell: "zone1"
        keyspace: "commerce"
        shard: "0"
        type: "rdonly"
    spec:
      terminationGracePeriodSeconds: 60000000
      securityContext:
        runAsUser: 1000
        fsGroup: 2000
      # set tuple values to more recognizable variables
      
      # affinity pod spec
      affinity:
        
      
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # prefer to be scheduled with same-cell vtgates
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vtgate"
                  cell: "zone1"
      
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # strongly prefer to stay away from same shard vttablets
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vttablet"
                  cell: "zone1"
                  keyspace: "commerce"
                  shard: "0"
      
          # prefer to stay away from any vttablets
          - weight: 10
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "vitess"
                  component: "vttablet"

      initContainers:
        
        
        - name: "init-mysql"
          image: "dockerhub.azk8s.cn/vitess/mysqlctld:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
            - name: vt
              mountPath: "/vttmp"
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              # set up the directories vitess needs
              mkdir -p /vttmp/bin
              mkdir -p /vtdataroot/tabletdata
        
              # copy necessary assets to the volumeMounts
              cp /vt/bin/mysqlctld /vttmp/bin/
              cp /bin/busybox /vttmp/bin/
              cp -R /vt/config /vttmp/
        
              # make sure the log files exist
              touch /vtdataroot/tabletdata/error.log
              touch /vtdataroot/tabletdata/slow-query.log
              touch /vtdataroot/tabletdata/general.log
        
              # remove the old socket file if it is still around
              rm -f /vtdataroot/tabletdata/mysql.sock
              rm -f /vtdataroot/tabletdata/mysql.sock.lock
        
        
        - name: init-vttablet
          image: "dockerhub.azk8s.cn/vitess/vtctl:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              # Split pod name (via hostname) into prefix and ordinal index.
              hostname=$(hostname -s)
              [[ $hostname =~ ^(.+)-([0-9]+)$ ]] || exit 1
              pod_prefix=${BASH_REMATCH[1]}
              pod_index=${BASH_REMATCH[2]}
              # Prepend cell name since tablet UIDs must be globally unique.
              uid_name=zone1-$pod_prefix
              # Take MD5 hash of cellname-podprefix.
              uid_hash=$(echo -n $uid_name | md5sum | awk "{print \$1}")
              # Take first 24 bits of hash, convert to decimal.
              # Shift left 2 decimal digits, add in index.
              tablet_uid=$((16#${uid_hash:0:6} * 100 + $pod_index))
              # Save UID for other containers to read.
              echo $tablet_uid > /vtdataroot/tabletdata/tablet-uid
              # Tell MySQL what hostname to report in SHOW SLAVE HOSTS.
              echo report-host=$hostname.vttablet > /vtdataroot/tabletdata/report-host.cnf
              # Orchestrator looks there, so it should match -tablet_hostname above.
        
              # make sure that etcd is initialized
              eval exec /vt/bin/vtctl $(cat <<END_OF_COMMAND
                -topo_implementation="etcd2"
                -topo_global_root=/vitess/global
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -logtostderr=true
                -stderrthreshold=0
                UpdateCellInfo
                -server_address="etcd-global-client.vitess:2379"
                "zone1"
              END_OF_COMMAND
              )

      containers:
        
        
        - name: mysql
          image: "dockerhub.azk8s.cn/library/percona:5.7.26"
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command: ["mysqladmin", "ping", "-uroot", "--socket=/vtdataroot/tabletdata/mysql.sock"]
            initialDelaySeconds: 60
            timeoutSeconds: 10
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
            - name: vt
              mountPath: /vt
            
            
          resources:
              limits:
                cpu: 250m
                memory: 500Mi
              
          env:
            - name: VTROOT
              value: "/vt"
            - name: VTDATAROOT
              value: "/vtdataroot"
            - name: GOBIN
              value: "/vt/bin"
            - name: VT_MYSQL_ROOT
              value: "/usr"
            - name: PKG_CONFIG_PATH
              value: "/vt/lib"
        
            - name: VT_DB_FLAVOR
              valueFrom:
                configMapKeyRef:
                  name: vitess-cm
                  key: db.flavor
        
          lifecycle:
            preStop:
              exec:
                command:
                  - "bash"
                  - "-c"
                  - |
                    set -x
        
                    # block shutting down mysqlctld until vttablet shuts down first
                    until [ $VTTABLET_GONE ]; do
        
                      # poll every 5 seconds to see if vttablet is still running
                      /vt/bin/busybox wget --spider localhost:15002/debug/vars
        
                      if [ $? -ne 0 ]; then
                        VTTABLET_GONE=true
                      fi
        
                      sleep 5
                    done
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
              if [ "$VT_DB_FLAVOR" = "percona" ]; then
                MYSQL_FLAVOR=Percona
              
              elif [ "$VT_DB_FLAVOR" = "mysql" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "mysql56" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "maria" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb103" ]; then
                MYSQL_FLAVOR=MariaDB103
              
              fi
              
              export MYSQL_FLAVOR
              
              
        
              eval exec /vt/bin/mysqlctld $(cat <<END_OF_COMMAND
                -logtostderr=true
                -stderrthreshold=0
                -tablet_dir "tabletdata"
                -tablet_uid "$(cat /vtdataroot/tabletdata/tablet-uid)"
                -socket_file "/vtdataroot/mysqlctl.sock"
                -init_db_sql_file "/vt/config/init_db.sql"
        
              END_OF_COMMAND
              )
        
        
        - name: vttablet
          image: "dockerhub.azk8s.cn/vitess/vttablet:helm-1.0.7-5"
          imagePullPolicy: IfNotPresent
          readinessProbe:
            httpGet:
              path: /debug/health
              port: 15002
            initialDelaySeconds: 60
            timeoutSeconds: 10
          livenessProbe:
            httpGet:
              path: /debug/status
              port: 15002
            initialDelaySeconds: 60
            timeoutSeconds: 10
          volumeMounts:
            - name: vtdataroot
              mountPath: "/vtdataroot"
            
            
            
        
          resources:
              limits:
                cpu: 250m
                memory: 500Mi
              
          ports:
            - name: web
              containerPort: 15002
            - name: grpc
              containerPort: 16002
          env:
            - name: VTROOT
              value: "/vt"
            - name: VTDATAROOT
              value: "/vtdataroot"
            - name: GOBIN
              value: "/vt/bin"
            - name: VT_MYSQL_ROOT
              value: "/usr"
            - name: PKG_CONFIG_PATH
              value: "/vt/lib"
            
        
            - name: VT_DB_FLAVOR
              valueFrom:
                configMapKeyRef:
                  name: vitess-cm
                  key: db.flavor
        
          lifecycle:
            preStop:
              exec:
                command:
                  - "bash"
                  - "-c"
                  - |
                    set -x
        
                    VTCTLD_SVC=vtctld.vitess:15999
                    VTCTL_EXTRA_FLAGS=()
        
                    master_alias_json=$(/vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC GetShard commerce/0)
                    master_cell=$(jq -r '.master_alias.cell' <<< "$master_alias_json")
                    master_uid=$(jq -r '.master_alias.uid' <<< "$master_alias_json")
                    master_alias=$master_cell-$master_uid
        
                    current_uid=$(cat /vtdataroot/tabletdata/tablet-uid)
                    current_alias=zone1-$current_uid
        
                    if [ $master_alias != $current_alias ]; then
                        # since this isn't the master, there's no reason to reparent
                        exit
                    fi
        
                    # TODO: add more robust health checks to make sure that we don't initiate a reparent
                    # if there isn't a healthy enough replica to take over
                    # - seconds behind master
                    # - use GTID_SUBTRACT
        
                    RETRY_COUNT=0
                    MAX_RETRY_COUNT=100000
                    hostname=$(hostname -s)
        
                    # retry reparenting
                    until [ $DONE_REPARENTING ]; do
        
        
        
                      # reparent before shutting down
                      /vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC PlannedReparentShard -keyspace_shard=commerce/0 -avoid_master=$current_alias
        
        
        
                      # if PlannedReparentShard succeeded, then don't retry
                      if [ $? -eq 0 ]; then
                        DONE_REPARENTING=true
        
                      # if we've reached the max retry count, exit unsuccessfully
                      elif [ $RETRY_COUNT -eq $MAX_RETRY_COUNT ]; then
                        exit 1
        
                      # otherwise, increment the retry count and sleep for 10 seconds
                      else
                        let RETRY_COUNT=RETRY_COUNT+1
                        sleep 10
                      fi
        
                    done
        
                    # delete the current tablet from topology. Not strictly necessary, but helps to prevent
                    # edge cases where there are two masters
                    /vt/bin/vtctlclient ${VTCTL_EXTRA_FLAGS[@]} -server $VTCTLD_SVC DeleteTablet $current_alias
        
        
        
        
          command: ["bash"]
          args:
            - "-c"
            - |
              set -ex
        
              if [ "$VT_DB_FLAVOR" = "percona" ]; then
                MYSQL_FLAVOR=Percona
              
              elif [ "$VT_DB_FLAVOR" = "mysql" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "mysql56" ]; then
                MYSQL_FLAVOR=MySQL56
              
              elif [ "$VT_DB_FLAVOR" = "maria" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb" ]; then
                MYSQL_FLAVOR=MariaDB
              
              elif [ "$VT_DB_FLAVOR" = "mariadb103" ]; then
                MYSQL_FLAVOR=MariaDB103
              
              fi
              
              export MYSQL_FLAVOR
              
              
              
        
              eval exec /vt/bin/vttablet $(cat <<END_OF_COMMAND
                -topo_implementation="etcd2"
                -topo_global_server_address="etcd-global-client.vitess:2379"
                -topo_global_root=/vitess/global
                -logtostderr
                -port 15002
                -grpc_port 16002
                -service_map "grpc-queryservice,grpc-tabletmanager,grpc-updatestream"
                -tablet_dir "tabletdata"
                -tablet-path "zone1-$(cat /vtdataroot/tabletdata/tablet-uid)"
                -tablet_hostname "$(hostname).vttablet"
                -init_keyspace "commerce"
                -init_shard "0"
                -init_tablet_type "rdonly"
                -health_check_interval "5s"
                -mysqlctl_socket "/vtdataroot/mysqlctl.sock"
                -enable_replication_reporter
        
        
                -init_db_name_override "commerce"
        
        
        
        
                
                
                  
                
                
                -app_pool_size="40"
                -dba_pool_size="20"
                -queryserver-config-max-result-size="10000"
                -queryserver-config-pool-size="24"
                -queryserver-config-query-timeout="30"
                -queryserver-config-stream-pool-size="100"
                -queryserver-config-transaction-cap="300"
                
              END_OF_COMMAND
              )
        
        
        - name: logrotate
          image: dockerhub.azk8s.cn/vitess/logrotate:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: general-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/general.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: error-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/error.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot
        
        
        - name: slow-log
          image: dockerhub.azk8s.cn/vitess/logtail:helm-1.0.7-5
          imagePullPolicy: IfNotPresent
        
          env:
          - name: TAIL_FILEPATH
            value: /vtdataroot/tabletdata/slow-query.log
        
          volumeMounts:
            - name: vtdataroot
              mountPath: /vtdataroot


      volumes:
        - name: vt
          emptyDir: {}
        
        
        


  volumeClaimTemplates:
    - metadata:
        name: vtdataroot
        annotations:
          null
          
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 500Mi
        

---
###################################
# vttablet PodDisruptionBudget
###################################
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: "zone1-commerce-0-rdonly"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: vitess
      component: vttablet
      cell: "zone1"
      keyspace: "commerce"
      shard: "0"
      type: "rdonly"

# conditionally add cron job
# set tuple values to more recognizable variables


       # range $tablet
     # range $shard
   # range $keyspace

 # range $cell


---

# shared ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: vitess-cm
data:
  backup.backup_storage_implementation: gcs
  backup.gcs_backup_storage_bucket: vitess-backups
  backup.gcs_backup_storage_root: vtbackups
  backup.s3_backup_aws_region: us-east-1
  backup.s3_backup_storage_bucket: vitess-backups
  backup.s3_backup_storage_root: vtbackups
  backup.s3_backup_server_side_encryption: AES256

  db.flavor: mysql56
 # end with config

